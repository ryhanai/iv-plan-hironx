\documentclass[11pt]{jarticle}
\setlength{\topmargin}{-15mm}
\setlength{\evensidemargin}{-2mm}
\setlength{\oddsidemargin}{3mm}
\setlength{\textheight}{24.5cm}
\setlength{\textwidth}{15cm}
%%
\usepackage[dvipdfm]{graphicx}
\usepackage{enumerate}

\usepackage{subfigure}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bm} % 数式の中のBold (\bm{})
\usepackage{amsmath} % 数式の中の改行 (\begin{gather} \\ )

\usepackage{listings,jlisting}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\newcommand {\figref}[1] {図\ref{#1}}
\newcommand{\tabref}[1] {表\ref{#1}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}

\renewcommand{\subfigtopskip}{1pt}
\renewcommand{\subfigbottomskip}{1pt}
\renewcommand{\subfigcapskip}{1pt}
\setlength{\floatsep}{6pt}           % 図表と図表の間のマージン
\setlength{\dblfloatsep}{6pt}        % ↑の二段組 version
\setlength{\textfloatsep}{6pt}       % 図表と本文の間のマージン
\setlength{\abovecaptionskip}{-2pt}   % 図表の caption と図表本体の間のマージン
\setlength{\belowcaptionskip}{2pt}   % 図表の caption 下部のマージン

\input amssym.def

\author{東京大学　情報理工学系研究科　稲葉研究室}
\title{(VPython版)HiroNX動作生成モジュール\\
使用説明書}
%\date{2010/4/10}

\begin{document}
\setlength{\baselineskip}{1.5zw}

\maketitle

% \tableofcontents

\section{概要}

Python対話環境において、幾何モデルを用いた動作生成システムを柔軟に構築するための
スクリプト群です．RtcHandleを用いて対話環境からRTC構成によるシステムの
各モジュールと通信を行うことで，システムの統合を行います．
RRT-connectによる双腕の干渉を考慮した動作計画機能を提供し，人手に
よる動作記述とプランナによる動作生成をスムーズに統合できます．
また，RTCとして，作業共通インタフェースを実装する動作生成モジュールとし
て利用することもできます．

http://openrtm.org/openrtm/ja/project/NEDO\_Intelligent\_PRJ\_HiroAccPrj\_5003

\section{ダウンロードとコンパイル}

\begin{lstlisting};
 $ cd iv-plan-hironx/iv_plan/scripts; ./install-debs.sh
 $ cd iv-plan-hironx/iv_plan/; make
 環境変数PYTHONPATHに iv-plan-hironx/iv_plan/srcを追加
\end{lstlisting}

環境によってVPythonが正しく動作しない場合があるため，また，debパッケージ
でインストールされるバージョンではサポートされていない機能を利用するため，
VPythonはUbuntu 10.04LTCの標準パッケージより新しいものにパッチを当て，コ
ンパイル済みのものを利用します．これは，make時にダウンロードします．
したがって，標準のpython-visualパッケージ
をインストールしている場合は，それがpython上で先にロードされることがない
ように注意する必要があります．
ikfastにより生成されたHIRO-NX用逆運動学計算のソースは同梱されており，PQP
のソースはmake時にダウンロードし，それぞれコンパイルされます．
それ以外に必要なものはaptコマンドでインストールします(install-deb.sh).

\section{開発・動作環境}

\begin{itemize}
 \item Ubuntu Linux 10.04 LTS 32bit/64bit
 \item OpenRTM-aist 1.0.0 (Python版)
\end{itemize}

\section{サンプルプログラムの実行}

% タスク記述，動作計画，認識および制御モジュールとの接続を
% １つのPythonシェル上で行う方法を説明します．

\begin{lstlisting}[label=src:branch]
 $ cd iv_scenario/src
 $ ipython test.py
 >>> test1()

 立体パズルデモ
 $ ipython puzzle.py
 >>> demo() # パズル配置を元に戻すのは reset_puzzle()

 シミュレーションによる部品の箱詰め
 $ ipython demo_wexpo.py
 >>> demo(False)
\end{lstlisting}

ウィンドウ操作は，右ドラッグで回転，中ドラッグでズームです．
プログラムの終了はCtrl+dでインタープリタを抜けた後，GUIの閉じるボタンを
押します．Ctrl+cはトラップされています．GUIの閉じるボタンを押すのが面倒
な場合はCtrl+\textbackslash でSIGQUITを送ることで終了させることができます．

Pythonシェル上でロボットの姿勢を変更したり，環境中の物体を移動させたり，
動作計画を行う場合の操作に関しては付録を参照してください．

\begin{figure}[tb]
 \begin{center}
  \includegraphics[width=0.8\linewidth]{figure/planner_scripts.png}
  \caption{動作生成モジュール}
  \label{fig:planner_scripts}
 \end{center}
\end{figure}

% \subsubsection{インタフェース}


 \section{HiroNX実機の利用}

本モジュールは，双腕ロボットの制御コマンド共通インタフェースにを利用し
て，実機に動作コマンドを送ります．したがって，実機を利用する場合は，
HinoNXInterfaceモジュールを必要とします．

  \subsection{HiroNXInterface}

  双腕ロボットの制御コマンドの共通インタフェースに準拠するHiroNX用制御モジュールです．
  詳細については，開発元である産業技術総合研究所のドキュメントを参照してください．

  http://www.openrtm.org/openrtm/en/node/4645

  \subsection{動作確認}

   % $ 起動スクリプト
   % IP/ホスト名の違いはどこを直せばよいか？

   最初にHiroNXInterface制御モジュールを起動，activate，接続し，利用可能な
   状態にします（詳細はHiroNXInterfaceのドキュメントを参照してください）．
   添付のスクリプトでも起動できます．
   \begin{lstlisting}[label=src:branch]
    $ cd iv_plan/scripts
    $ ./run_hironx_interface.sh 
   \end{lstlisting}
   iv\_plan/scripts以下のスクリプトは，ローカルのファイルシステム非依存で
   各モジュールのパスを検出するため，ROSのツールであるrospackを使います．
   rospackを利用できない場合は適宜，修正してください．
   % もし，コンポーネントが上手く接続およびactivateされない場合
   % は，./comcon.shおよび./comact.shを再度実行してください．
   HiroNXInterfaceモジュールは起動後GUI上の「RTC Status」が緑になった状態で
   「Set up Robot」ボタンを押しRTCまわりの初期化を行う必要がある点に注意
   してください．

   HiroNXIntarfaceの起動および，ロボットのジョイントキャリブレーションが
   終了した状態で，実機との通信テストを行います．
   
   \begin{lstlisting}[label=src:branch]
    $ cd iv_scenario/src
    demo_wexpo.pyのreal_robotをTrueに変更します．
    
    $ ipython demo_wexpo.py
    >>> rr.get_joint_angles() # 実機の関節角度列を取得
    >>> r.prepare() # シミュレータ内で姿勢を変更
    >>> sync() # 実機の姿勢をシミュレータにあわせる(実機が動くので注意)
   \end{lstlisting}

   外部RTCとの通信にはRtcHandleを利用しています．

   (http://staff.aist.go.jp/t.suehiro/rtm/rtc\_handle.html)
   
   動作生成側からHiroNX体内のRTCや認識などのモジュールにアクセスする必要
   があります．そのための検索先ネームサーバはPythonプログラムを起動す
   るディレクトリにあるrtc.confから取得します．以下のようにiv\_scenario
   ディレクトリでpythonプログラムを起動する場合，iv\_scenario/rtc.confが
   読み込まれます．外部モジュールと通信ができない場合は，rtc.confを確認
   してください．
   また，接続先RTコンポーネントのパスは，interface\_wexpo.pyに定義されて
   います．portdefsを利用している環境にあわせて修正してください．
   

 % \section{設計方針}

 % \section{インタフェース}


 \section{RTコンポーネントとしての利用}

 本スクリプト群は，ロボットの環境と外部モジュールとの通信支援機能を提供しま
 す．これらを異なるレイヤでモジュール化するRTCもあわせて提供します．
 例えば，センサでの認識結果を世界座標に変換する「座標変換モジュール」，
 テーブル上のスキャン動作を含めた「ハンドスキャンによる対象物認識モジュー
 ル」，アームの「動作計画モジュール」といった利用ができます．
 これらは，「手先カメラを用いた双腕ロボットによるマニピュレーションシス
 テム」で用いている機能の一部をモジュールとしてくくり出しているといえま
 す．

% \begin{itemize}
%  \item 基本的に，ロボットクラス，ロボットインスタンスごとのカスタマイズは既存クラスを拡張することで行います．
%  \item robot.pyからhironx.py
%  \item hironx\_params.py
%        個体差がある各種transformと，利用する外部モジュール定義
%  \item 環境モデルの定義 \\
%        (pythonのデータ構造で与える．scene\_object.py)
%  \item 他の機能として，VRMLのローダ，センサ取り付け位置の推定機能があり
%        ます.
% \end{itemize}

\newpage

\appendix
\section{VPython環境でのプログラミング}

フレームやロボット，環境中の物体操作等をpython上で行う方法について説明し
ます．

\begin{verbatim}

# 1, pythonを使う

dir(r) # 関数やメソッドの一覧
r. [TAB] # メソッド名等の補間（ipythonの機能）
help(r) # 引数や説明

# コマンドライン
# Ctrl+c
# Ctrl+p / Ctrl+n
# Ctrl+r

# 2, 環境中の物体操作

env
env.get_objects() # 環境中の物体一覧
[x.name for x in env.get_objects()] # 物体名一覧

# 物体は名前で管理されている。
# 同じ名前の物体は追加できないので、一度削除するか、名前を変えて追加する。
a = env.get_object('A0') # 名前で物体取得
env.delete_object('A0') # 物体の削除

f = b.where() # 物体のフレーム(位置と姿勢)を取得

# ロボットの移動、回転 ( world=>baselinkの座標変換の変更 )
r.go_pos(-150,500,0)  # 2D座標, (x,y,theta)
r.go_pos(-150,0,pi/2) # 横を向く

# 3, 自作サンプルの書き方

PYTHONPATHを設定するので，作業ディレクトリは自由です．
iv_scenario/src/test.py
を参考にしてください．
ただし，ネームサーバ情報をカレントディレクトリにある
rtc.confから読取る点に注意してください．

# 4, ロボットの姿勢の操作

# joint, linkの取得
r
r.get_joints()
r.get_links()
r.get_link('RARM_JOINT0_Link')

# ジョイント名の取得
map(lambda x: x.name, r.get_joints())
[x.name for x in r.get_joints()]

# 関節角度の表示
r.get_joint_angles()
# これは下のコードと同じ
[x.angle for x in r.get_joints]

# 腕だけ
angles = r.get_joint_angles(joints='rarm')
r.set_joint_angles(angles, joints='larm')

# ハンドだけ
r.get_joint_angles(joints='rhand')
r.set_joint_angles(angles, joints='lhand')

# 関節１つを変える
r.get_joint_angle(0) # ID
r.set_joint_angle(0, 0.5) # IDと角度[rad]

# 初期姿勢に戻す
r.reset_pose() # r.prepare()も同じ姿勢

# あらかじめいくつかの姿勢が定義されている
r.poses
r.poses.keys()

# 手を動かす
r.grasp(width=80)  # 指の幅80[mm]
r.grasp2(0.5)      # 関節角度[0.5,-0.5, -0.5, 0.5]
# ただし，grasp2は根元の関節が少し内側へ入る
# 把持対象にぴったりあうように角度を指定すればよい．

# 5, 座標系(frame)について
# 3x3回転行列と3次元ベクトル = 4x4の同次数行列
# euler角, 自由軸回転, quaternion

help(VECTOR)
help(MATRIX)
help(FRAME)

# 値の生成(constructor)
VECTOR()
MATRIX()
FRAME()
v=VECTOR(vec=[100,0,0])
MATRIX(angle=pi/2, axis=VECTOR(vec=[0,0,1]))
MATRIX(c=pi/2) # a,b,cを同時に指定できないので注意
m=MATRIX([[1,0,0],[0,1,0],[0,0,1]])
FRAME()

frm.mat # 姿勢部分
frm.vec # 位置部分

# 演算
v*v # ベクトル積
dot(v,v) # 内積
v+v # 和
2*v # スカラー倍
# 行列は姿勢表現専用（直行行列）
m*m # 積
-m # 逆行列
# -mはじ実装は転置行列
# スカラー倍、行列和は定義されない(配列の結合解釈される)

# 姿勢表現間の変換
m.abc() # 行列=>euler
m.rot_axis() # 行列=>自由軸回転
# euler=>回転行列、自由軸回転=>回転行列は上記のMATRIXのコンストラクタ

# 位置と姿勢を合わせた表現（同時行列）
FRAME(mat=m, vec=v)
FRAME(xyzabc=[x,y,z,a,b,c])

f=FRAME(vec=[500,0,1000])
show_frame(f)
f.mat = MATRIX(a=pi/4)
show_frame(f)

# 座標系の親子構造
FRAME.affix() # 座標系の親子関係の定義
FRAME.unfix() # 座標系の親子関係の削除
FRAME.set_trans() # 親子間の座標変換の設定
f.rel_trans # 親子間の座標変換の取得

# 物体追加
# 表示用形状とFRAMEを作り、適当な親座標系の子FRAMEとして、座標系ツリーに挿入する
env.insert_object('box2') # 物体追加
env.delete_object('box2') # 物体削除(子フレームの物体も削除される)

# 6, 逆運動学計算

# 手首位置，姿勢の取得
r.fk() # 順運動学計算，現在の手先FRAMEを返す．デフォルトは右手．
r.fk(arm='left') # 左手は明示的に引数で指定する
r.ik(afrms) # 目標位置へ手を伸ばすための関節角度を計算する
help(r.ik)
# - IKは目標手先FRAMEの集合を引数にとり、
#   初期姿勢から関節空間での重み付き距離順に並べた解の列を返す
#   目標手先フレーム１つを引数に指定してもよい
# - 解が存在しなければNone
# - ほとんどの場合、最初の解を採用すればよい

# 腰を使う(腰yaw軸を使うと手の届く範囲が大きく広がる)
# 腰を回す
# 腕の姿勢を変える
# 他の解も表示してみる
# 物体をハンドに固定する,解除する

# 手先軌道での動作生成
# 軌道の作成
traj = CoordinateObjects('trajectory')
traj.append( ... ) # 適当なフレームを追加する
env.insert_object(traj, FRAME(), env.get_world()) # 世界座標相対で軌道を定義
traj.coords

# 削除したいときは
env.delete_object('trajectory')

# 7, 実機を動かす

# 実機とのインタフェースオブジェクトの生成
# インタフェースオブジェクトの拡張
# force sensor, ARtoolkit, tf, OpenRAVE

sync() # デフォルトは4[sec]で実機をモデルに同期させる
sync(duration=3.0) # 時間を変える

# Linkに沿った座標変換
# 認識結果は、カメラ=>対象物の座標変換であるので、
# 世界座標=>対象物の座標変換に直す

# 動作計画
# RRT-connectによる動作計画
# 軌道の表示
# 軌道の最適化
# 実行
# 干渉チェック
# 対象物の追加例, padding

\end{verbatim}

% \addcontentsline{toc}{chapter}{参考文献}
% \markboth{参考文献}{参考文献}
% \bibliographystyle{junsrt}
% \bibliography{p2009}


\end{document}
